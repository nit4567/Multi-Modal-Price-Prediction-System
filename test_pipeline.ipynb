{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN4OTgPXebIE0QhQ1I50jbc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Embedding creation for test dataset"],"metadata":{"id":"eiASi10npb9i"}},{"cell_type":"code","source":["#################################################################################\n","import numpy as np\n","import re\n","import pandas as pd\n","\n","# constants\n","OZ_TO_ML = 29.5735\n","OZ_TO_G  = 28.3495\n","L_TO_ML  = 1000.0\n","KG_TO_G  = 1000.0\n","LB_TO_G  = 453.59237\n","\n","\n","UNIT_MAP = {\n","    \"oz\": \"oz\", \"ounce\": \"oz\", \"ounces\": \"oz\",\n","    \"fl oz\": \"fl_oz\", \"floz\": \"fl_oz\", \"fl.oz\": \"fl_oz\",\n","    \"ml\": \"ml\", \"l\": \"l\", \"litre\": \"l\", \"liter\": \"l\",\n","    \"g\": \"g\", \"kg\": \"kg\",\n","    \"pack\": \"pack\", \"count\": \"count\", \"ct\": \"count\", \"piece\": \"count\"\n","}\n","\n","def extract_value_and_unit(text):\n","    \"\"\"\n","    Extract 'value' and 'unit' (explicit or implicit) from product text.\n","    Requires 'Value:' and 'Unit:' to appear on their own lines.\n","    \"\"\"\n","    t = str(text).lower()\n","    out = {\"value\": np.nan, \"unit\": None, \"has_value\": 0, \"has_unit\": 0}\n","\n","    # 1Ô∏è‚É£ Explicit \"Value:\" label at start of line\n","    m = re.search(r'(?m)^[ \\t]*value:\\s*(\\d+(?:\\.\\d+)?)', t)\n","    if m:\n","        out[\"value\"] = float(m.group(1))\n","        out[\"has_value\"] = 1\n","\n","    # 2Ô∏è‚É£ Explicit \"Unit:\" label at start of line\n","    m = re.search(r'(?m)^[ \\t]*unit:\\s*([^\\n\\r]*)', t)\n","    if m:\n","        unit_raw = m.group(1).strip()\n","        unit_clean = UNIT_MAP.get(unit_raw.replace('.', '').replace(' ', ''), unit_raw)\n","        out[\"unit\"] = unit_clean\n","        out[\"has_unit\"] = 1\n","\n","    # 3Ô∏è‚É£ Implicit numeric + unit pattern (fallback)\n","    if not out[\"has_unit\"]:\n","        m = re.search(r'(\\d+(?:\\.\\d+)?)\\s*(fl\\.?\\s?oz|ounce|ounces|oz|ml|g|kg|l)\\b', t)\n","        if m:\n","            val = float(m.group(1))\n","            unit_raw = m.group(2).replace('.', '').replace(' ', '')\n","            out[\"value\"] = val if np.isnan(out[\"value\"]) else out[\"value\"]\n","            out[\"unit\"] = UNIT_MAP.get(unit_raw, unit_raw)\n","            out[\"has_unit\"] = 1\n","            out[\"has_value\"] = 1\n","\n","    return out\n","\n","\n","def add_value_unit_features(df, text_col=\"catalog_content\"):\n","    \"\"\"\n","    Adds 'value_only', 'unit_only', 'has_value', and 'has_unit' columns.\n","    \"\"\"\n","    extracted = df[text_col].fillna(\"\").apply(extract_value_and_unit)\n","    extracted_df = pd.DataFrame(list(extracted))\n","\n","    df[\"value\"] = extracted_df[\"value\"]\n","    df[\"unit\"] = extracted_df[\"unit\"]\n","    df[\"has_value\"] = extracted_df[\"has_value\"]\n","    df[\"has_unit\"] = extracted_df[\"has_unit\"]\n","\n","    return df\n","\n","UNIT_MAP_CLEAN = {\n","    # --- volume ---\n","    \"ml\": \"ml\", \"millilitre\": \"ml\", \"milliliter\": \"ml\", \"mililitro\": \"ml\", \"ltr\": \"l\", \"l\": \"l\", \"liters\": \"l\", \"2.5 gal.\": \"gal\",\n","    \"fl_oz\": \"fl_oz\", \"fl ounce\": \"fl_oz\", \"fl oz\": \"fl_oz\", \"fluid ounce\": \"fl_oz\", \"fluid ounces\": \"fl_oz\", \"fluid ounce(s)\": \"fl_oz\", \"20 oz.\": \"oz\",\n","\n","    # --- weight ---\n","    \"g\": \"g\", \"gram\": \"g\", \"grams\": \"g\", \"gramm\": \"g\", \"gr\": \"g\", \"grams(gm)\": \"g\",\n","    \"kg\": \"kg\", \"pound\": \"lb\", \"pounds\": \"lb\", \"lb\": \"lb\",\n","\n","    # --- count / packaging ---\n","    \"pack\": \"pack\", \"packs\": \"pack\", \"per package\": \"pack\", \"per box\": \"pack\",\n","    \"count\": \"count\", \"ct\": \"count\", \"each\": \"count\", \"each / pack: 1\": \"count\",\n","    \"bag\": \"pack\", \"box\": \"pack\", \"box/12\": \"pack\", \"carton\": \"pack\", \"case\": \"pack\",\n","    \"bottle\": \"count\", \"bottles\": \"count\", \"jar\": \"count\", \"can\": \"count\", \"capsule\": \"count\",\n","    \"pouch\": \"count\", \"bucket\": \"count\", \"k-cups\": \"count\", \"ziplock bags\": \"count\", \"paper cupcake liners\": \"count\", \"tea bags\": \"count\",\n","\n","    # --- others (dimensional / irrelevant) ---\n","    \"in\": \"in\", \"sq ft\": \"sq_ft\", \"foot\": \"ft\", \"cm/inch)\": \"cm_inch\",\n","\n","    # --- noise / invalid ---\n","    \"none\": None, \"\": None, \"-\": None, \"---\": None, \"1\": None, \"24\": None,\n","    \"product_weight\": None, \"units\": None,\n","    \"1 pk. color(s): -black. product type: -permanent. pack quantity: -1. tip type: -chisel. dimensions: overall product weight: -0.06 lbs.\": None,\n","    \"comes as a single 0.1 oz stick for on-the-go use\": None,\n","    \"unit√†\": None,\n","    \"7,2 oz\": \"oz\"\n","}\n","\n","def normalize_unit(unit):\n","    if pd.isna(unit) or not isinstance(unit, str):\n","        return None\n","    u = unit.strip().lower()\n","    u = u.replace('.', '').replace('(', '').replace(')', '').replace(':', '').strip()\n","    return UNIT_MAP_CLEAN.get(u, u)  # fallback: return itself if not found\n","\n","UNIT_FINAL_MAP = {\n","    \"oz\": \"oz\",\n","    \"fl_oz\": \"fl_oz\",\n","    \"count\": \"count\",\n","    \"lb\": \"lb\",\n","    \"g\": \"g\",\n","    \"ml\": \"ml\",\n","    \"l\": \"l\",\n","    \"kg\": \"kg\",\n","    \"pack\": \"pack\",\n","    \"per carton\": \"pack\",\n","    \"sq_ft\": \"sq_ft\",\n","    \"ft\": \"ft\",\n","    \"in\": \"in\",\n","    \"8\": None, # Map '8' to None\n","    \"gramsgm\": \"g\",\n","    None: None\n","}\n","\n","UNIT_CATEGORY_MAP = {\n","    \"oz\": \"weight\",\n","    \"lb\": \"weight\",\n","    \"g\": \"weight\",\n","    \"kg\": \"weight\",\n","    \"ml\": \"volume\",\n","    \"l\": \"volume\",\n","    \"fl_oz\": \"volume\",\n","    \"count\": \"count\",\n","    \"pack\": \"count\",\n","    \"sq_ft\": \"dimension\",\n","    \"ft\": \"dimension\",\n","    \"in\": \"dimension\",\n","    None: \"unknown\"\n","}\n","\n","\n","def clean_catalog_text(text):\n","    \"\"\"\n","    Removes lines starting with 'Value:' or 'Unit:' (case-insensitive) from catalog text.\n","    Only removes if they are at the beginning of a line.\n","    \"\"\"\n","    pattern = r'(?im)^[ \\t]*(value:.*|unit:.*)$'\n","    cleaned = re.sub(pattern, '', str(text))\n","    return cleaned.strip()\n","\n","def qty_to_base(qty, unit_final, unit_category):\n","    \"\"\"Return (qty_in_base, base_type) where base_type is 'ml', 'g', or 'count' or None\"\"\"\n","    if pd.isna(qty) or qty <= 0 or unit_final is None:\n","        return (np.nan, None)\n","    u = str(unit_final).lower()\n","    if unit_category == 'volume':\n","        if u in ('ml',):\n","            return (qty, 'ml')\n","        if u in ('l', 'ltr'):\n","            return (qty * L_TO_ML, 'ml')\n","        if u in ('fl_oz','floz','fl ounce','fluid ounce','fluid ounces'):\n","            return (qty * OZ_TO_ML, 'ml')\n","        if u == 'oz':  # ambiguous: treat by category; here category=volume so ml\n","            return (qty * OZ_TO_ML, 'ml')\n","    if unit_category == 'weight':\n","        if u in ('g','gram','grams','gr','gramsgm'):\n","            return (qty, 'g')\n","        if u in ('kg',):\n","            return (qty * KG_TO_G, 'g')\n","        if u in ('lb','pound','pounds'):\n","            return (qty * LB_TO_G, 'g')\n","        if u == 'oz':  # treat ounce as weight here\n","            return (qty * OZ_TO_G, 'g')\n","    if unit_category == 'count':\n","        return (qty, 'count')\n","    return (np.nan, None)\n","\n","def feat_eng(data):\n","    \"\"\"Applies feature engineering steps to the input DataFrame.\"\"\"\n","\n","    # 1) price_per_unit (raw)\n","\n","    # 2) standardized base price (price per ml or per g)\n","    # Ensure 'unit_final' and 'unit_category' columns exist\n","    if 'unit_final' not in data.columns or 'unit_category' not in data.columns:\n","         raise ValueError(\"DataFrame must contain 'unit_final' and 'unit_category' columns before calling feat_eng.\")\n","\n","    qty_base = data.apply(lambda r: qty_to_base(r['value'], r['unit_final'], r['unit_category']), axis=1)\n","    data['qty_base'] = [q[0] for q in qty_base]\n","    data['base_type'] = [q[1] for q in qty_base]\n","\n","    # 4) simple text features (use catalog_content_clean or catalog_content which you replaced)\n","    def text_feats(t):\n","        t = str(t)\n","        words = re.findall(r'\\w+', t)\n","        word_count = len(words)\n","        char_count = len(t)\n","        avg_word_len = np.mean([len(w) for w in words]) if words else 0\n","        bullet_count = len(re.findall(r'bullet', t, flags=re.I))  # simple bullet marker\n","        digits = len(re.findall(r'\\d', t))\n","        return pd.Series([word_count, char_count, avg_word_len, bullet_count, digits])\n","\n","    # Ensure 'catalog_content' column exists\n","    if 'catalog_content' not in data.columns:\n","         raise ValueError(\"DataFrame must contain 'catalog_content' column before calling feat_eng.\")\n","\n","    data[['word_count','char_count','avg_word_len','bullet_count','num_digits']] = data['catalog_content'].apply(text_feats)\n","\n","    # 5) keyword flags\n","    keywords = {\n","        'organic': 'is_organic',\n","        'gluten-free': 'is_gluten_free',\n","        'gluten free': 'is_gluten_free',\n","        'sugar-free': 'is_sugar_free',\n","        'sugar free': 'is_sugar_free',\n","        'vegan': 'is_vegan',\n","        'new': 'is_new',\n","        'pack': 'has_pack_word',\n","        'bundle': 'has_bundle'\n","    }\n","    for kw, col in keywords.items():\n","        data[col] = data['catalog_content'].str.contains(re.escape(kw), case=False, na=False).astype(int)\n","\n","    return data # Return the modified DataFrame\n","def process_FE(data):\n","  data = add_value_unit_features(data)\n","\n","  data[\"unit_normalized\"] = data[\"unit\"].apply(normalize_unit)\n","  data[\"unit_final\"] = data[\"unit_normalized\"].map(UNIT_FINAL_MAP) # Applied to data DataFrame\n","  data[\"unit_category\"] = data[\"unit_final\"].map(UNIT_CATEGORY_MAP).fillna(\"unknown\") # Applied to data DataFrame\n","  data['catalog_content'] = data['catalog_content'].apply(clean_catalog_text)\n","\n","  # Drop unneeded columns to save space\n","  cols_to_drop = [\"unit\", \"unit_normalized\"]\n","  data = data.drop(columns=cols_to_drop)\n","  data = feat_eng(data)\n","  return data\n"],"metadata":{"id":"kJSXvtfriXTi","executionInfo":{"status":"ok","timestamp":1760266636288,"user_tz":-330,"elapsed":550,"user":{"displayName":"Nitish Rishi","userId":"10781579516426583515"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["!pip install git+https://github.com/openai/CLIP.git ftfy\n","import clip\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"448EQFHYlwkN","executionInfo":{"status":"ok","timestamp":1760266891566,"user_tz":-330,"elapsed":20270,"user":{"displayName":"Nitish Rishi","userId":"10781579516426583515"}},"outputId":"32dc75b6-b437-4570-d63b-2acc8c59cfbc"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/openai/CLIP.git\n","  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-1h1doear\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-1h1doear\n","  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting ftfy\n","  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (25.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (4.67.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (2.8.0+cu126)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (0.23.0+cu126)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy) (0.2.14)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->clip==1.0) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->clip==1.0) (11.3.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->clip==1.0) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->clip==1.0) (3.0.3)\n","Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: clip\n","  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369490 sha256=167858d6b1aedcf7fec93d62fb38298f923aaba4faefaf066817e301abd72f8d\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-yrjnhz3t/wheels/35/3e/df/3d24cbfb3b6a06f17a2bfd7d1138900d4365d9028aa8f6e92f\n","Successfully built clip\n","Installing collected packages: ftfy, clip\n","Successfully installed clip-1.0 ftfy-6.3.1\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XyqcyOdZgaaw","executionInfo":{"status":"ok","timestamp":1760266916774,"user_tz":-330,"elapsed":25200,"user":{"displayName":"Nitish Rishi","userId":"10781579516426583515"}},"outputId":"4a32ab13-47c7-45dd-dc98-85a7c06b029a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":[" #-------------------------\n","# IMPROVED PIPELINE: Add CLIP Text + Alignment\n","# -------------------------\n","import torch\n","import numpy as np\n","from tqdm import tqdm\n","import os\n","import pandas as pd\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Define base directory\n","base_dir = '/content/drive/MyDrive/amazon_ml_challenge'\n","\n","#\n","# -------------------------\n","# Load and process data\n","# -------------------------\n","# train_csv_path = os.path.join(base_dir, 'test.csv')\n","# data = pd.read_csv(train_csv_path)\n"]},{"cell_type":"code","source":["# data = process_FE(data)\n","\n","# # Impute missing values\n","# data['value'] = data['value'].fillna(-1)\n","# median_qty_base = data['qty_base'].median()\n","# data['qty_base'] = data['qty_base'].fillna(median_qty_base)\n","# data['base_type'] = data['base_type'].fillna('missing')\n","# data['unit_final'] = data['unit_final'].fillna('unknown')\n","\n","# print(\"‚úÖ Data loaded and processed\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FDMymU6YicDj","executionInfo":{"status":"ok","timestamp":1760266706071,"user_tz":-330,"elapsed":34283,"user":{"displayName":"Nitish Rishi","userId":"10781579516426583515"}},"outputId":"ee92a570-69a1-410e-883f-b96e0aaa0258"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Data loaded and processed\n"]}]},{"cell_type":"code","source":["# save_path_drive = os.path.join(base_dir, \"processed_fe+textpre_test_dataset.csv\")\n","# data.to_csv(save_path_drive, index=False)\n","# print(f\"‚úÖ Processed data saved to: {save_path_drive}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ol4nBrsFia9W","executionInfo":{"status":"ok","timestamp":1760266709558,"user_tz":-330,"elapsed":3479,"user":{"displayName":"Nitish Rishi","userId":"10781579516426583515"}},"outputId":"8ac1c165-ba5c-47ee-8686-fb0d42f20f56"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Processed data saved to: /content/drive/MyDrive/amazon_ml_challenge/processed_fe+textpre_test_dataset.csv\n"]}]},{"cell_type":"code","source":["processed_csv_path = os.path.join(base_dir, \"processed_fe+textpre_test_dataset.csv\")\n","data = pd.read_csv(processed_csv_path)\n","print(f\"‚úÖ Processed data loaded from: {processed_csv_path}\")\n","display(data.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":533},"id":"piEV_HwojlGq","executionInfo":{"status":"ok","timestamp":1760266933325,"user_tz":-330,"elapsed":3556,"user":{"displayName":"Nitish Rishi","userId":"10781579516426583515"}},"outputId":"e72bc5ea-6caa-4119-da16-10593518f755"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Processed data loaded from: /content/drive/MyDrive/amazon_ml_challenge/processed_fe+textpre_test_dataset.csv\n"]},{"output_type":"display_data","data":{"text/plain":["   sample_id                                    catalog_content  \\\n","0     100179  Item Name: Rani 14-Spice Eshamaya's Mango Chut...   \n","1     245611  Item Name: Natural MILK TEA Flavoring extract ...   \n","2     146263  Item Name: Honey Filled Hard Candy - Bulk Pack...   \n","3      95658  Item Name: Vlasic Snack'mm's Kosher Dill 16 Oz...   \n","4      36806  Item Name: McCormick Culinary Vanilla Extract,...   \n","\n","                                          image_link  value  has_value  \\\n","0  https://m.media-amazon.com/images/I/71hoAn78AW...   10.5          1   \n","1  https://m.media-amazon.com/images/I/61ex8NHCIj...    2.0          1   \n","2  https://m.media-amazon.com/images/I/61KCM61J8e...   32.0          1   \n","3  https://m.media-amazon.com/images/I/51Ex6uOH7y...    2.0          1   \n","4  https://m.media-amazon.com/images/I/71QYlrOMoS...   32.0          1   \n","\n","   has_unit unit_final unit_category   qty_base base_type  ...  avg_word_len  \\\n","0         1         oz        weight  297.66975         g  ...      4.687204   \n","1         1      fl_oz        volume   59.14700        ml  ...      4.970696   \n","2         1         oz        weight  907.18400         g  ...      4.685039   \n","3         1      count         count    2.00000     count  ...      3.307692   \n","4         1      fl_oz        volume  946.35200        ml  ...      5.101695   \n","\n","   bullet_count  num_digits  is_organic  is_gluten_free  is_sugar_free  \\\n","0           5.0        20.0           0               1              0   \n","1           6.0         9.0           0               1              0   \n","2           5.0        11.0           0               0              0   \n","3           0.0         3.0           0               0              0   \n","4           5.0        13.0           0               1              0   \n","\n","   is_vegan  is_new  has_pack_word  has_bundle  \n","0         1       0              1           0  \n","1         0       1              1           0  \n","2         0       0              1           0  \n","3         0       0              1           0  \n","4         0       0              0           0  \n","\n","[5 rows x 22 columns]"],"text/html":["\n","  <div id=\"df-a99a27e1-5886-4d1f-865a-4137856b0850\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sample_id</th>\n","      <th>catalog_content</th>\n","      <th>image_link</th>\n","      <th>value</th>\n","      <th>has_value</th>\n","      <th>has_unit</th>\n","      <th>unit_final</th>\n","      <th>unit_category</th>\n","      <th>qty_base</th>\n","      <th>base_type</th>\n","      <th>...</th>\n","      <th>avg_word_len</th>\n","      <th>bullet_count</th>\n","      <th>num_digits</th>\n","      <th>is_organic</th>\n","      <th>is_gluten_free</th>\n","      <th>is_sugar_free</th>\n","      <th>is_vegan</th>\n","      <th>is_new</th>\n","      <th>has_pack_word</th>\n","      <th>has_bundle</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>100179</td>\n","      <td>Item Name: Rani 14-Spice Eshamaya's Mango Chut...</td>\n","      <td>https://m.media-amazon.com/images/I/71hoAn78AW...</td>\n","      <td>10.5</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>oz</td>\n","      <td>weight</td>\n","      <td>297.66975</td>\n","      <td>g</td>\n","      <td>...</td>\n","      <td>4.687204</td>\n","      <td>5.0</td>\n","      <td>20.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>245611</td>\n","      <td>Item Name: Natural MILK TEA Flavoring extract ...</td>\n","      <td>https://m.media-amazon.com/images/I/61ex8NHCIj...</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>fl_oz</td>\n","      <td>volume</td>\n","      <td>59.14700</td>\n","      <td>ml</td>\n","      <td>...</td>\n","      <td>4.970696</td>\n","      <td>6.0</td>\n","      <td>9.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>146263</td>\n","      <td>Item Name: Honey Filled Hard Candy - Bulk Pack...</td>\n","      <td>https://m.media-amazon.com/images/I/61KCM61J8e...</td>\n","      <td>32.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>oz</td>\n","      <td>weight</td>\n","      <td>907.18400</td>\n","      <td>g</td>\n","      <td>...</td>\n","      <td>4.685039</td>\n","      <td>5.0</td>\n","      <td>11.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>95658</td>\n","      <td>Item Name: Vlasic Snack'mm's Kosher Dill 16 Oz...</td>\n","      <td>https://m.media-amazon.com/images/I/51Ex6uOH7y...</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>count</td>\n","      <td>count</td>\n","      <td>2.00000</td>\n","      <td>count</td>\n","      <td>...</td>\n","      <td>3.307692</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>36806</td>\n","      <td>Item Name: McCormick Culinary Vanilla Extract,...</td>\n","      <td>https://m.media-amazon.com/images/I/71QYlrOMoS...</td>\n","      <td>32.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>fl_oz</td>\n","      <td>volume</td>\n","      <td>946.35200</td>\n","      <td>ml</td>\n","      <td>...</td>\n","      <td>5.101695</td>\n","      <td>5.0</td>\n","      <td>13.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows √ó 22 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a99a27e1-5886-4d1f-865a-4137856b0850')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a99a27e1-5886-4d1f-865a-4137856b0850 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a99a27e1-5886-4d1f-865a-4137856b0850');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-11767af6-7d61-4400-82bc-2d1458b1403a\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-11767af6-7d61-4400-82bc-2d1458b1403a')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-11767af6-7d61-4400-82bc-2d1458b1403a button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe"}},"metadata":{}}]},{"cell_type":"code","source":["# -------------------------\n","# 1Ô∏è‚É£ Load image embeddings (already aligned to train.csv!)\n","# -------------------------\n","img_data = os.path.join(base_dir, \"full_image_embeddings_testset.npy\")\n","img_embeddings = np.load(\"/content/full_image_embeddings_test.npy\")\n","img_tensor = torch.tensor(np.nan_to_num(img_embeddings, nan=0.0), dtype=torch.float)\n","print(f\"‚úÖ Image embeddings loaded: {img_tensor.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4vWIpXf8m4cg","executionInfo":{"status":"ok","timestamp":1760267020307,"user_tz":-330,"elapsed":566,"user":{"displayName":"Nitish Rishi","userId":"10781579516426583515"}},"outputId":"5f211a5e-333e-4a82-e8cd-4b7bd5512413"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Image embeddings loaded: torch.Size([75000, 512])\n"]}]},{"cell_type":"code","source":["\n","# -------------------------\n","# 2Ô∏è‚É£ Load text+structured embeddings\n","# -------------------------\n","train_input_final_path = os.path.join(base_dir, 'test_input_final.pt')\n","train_text_embd_data = torch.load(train_input_final_path)\n","\n","train_text_struct = train_text_embd_data['train_input']  # MiniLM + structured\n","sample_ids = train_text_embd_data['sample_ids']\n","\n"],"metadata":{"id":"xtXqtZ_xjysq","executionInfo":{"status":"ok","timestamp":1760267128904,"user_tz":-330,"elapsed":7648,"user":{"displayName":"Nitish Rishi","userId":"10781579516426583515"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["\n","\n","print(f\"‚úÖ Text+Structured loaded: {train_text_struct.shape}\")\n","\n","# -------------------------\n","# 2.5Ô∏è‚É£ VERIFY ORDER (important sanity check!)\n","# -------------------------\n","print(\"\\nüîç Verifying alignment...\")\n","print(f\"Train CSV has {len(data)} rows\")\n","print(f\"Image embeddings has {len(img_tensor)} rows\")\n","print(f\"Sample IDs has {len(sample_ids)} entries\")\n","\n","# Check if sample_ids match train.csv order\n","if (data['sample_id'].values[:len(sample_ids)] == np.array(sample_ids)).all():\n","    print(\"‚úÖ Sample IDs are in train.csv order - perfect!\")\n","    data_final = data.copy() # only used for getting text\n","else:\n","    print(\"‚ö†Ô∏è  Sample IDs are NOT in train.csv order - reordering...\")\n","    data_final = data.set_index('sample_id').loc[sample_ids].reset_index()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U6nRLdUIGNtz","executionInfo":{"status":"ok","timestamp":1760267133893,"user_tz":-330,"elapsed":6,"user":{"displayName":"Nitish Rishi","userId":"10781579516426583515"}},"outputId":"22f50013-7cc3-4c45-9f70-e10456e18ee6"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Text+Structured loaded: torch.Size([75000, 403])\n","\n","üîç Verifying alignment...\n","Train CSV has 75000 rows\n","Image embeddings has 75000 rows\n","Sample IDs has 75000 entries\n","‚úÖ Sample IDs are in train.csv order - perfect!\n"]}]},{"cell_type":"code","source":["\n","# -------------------------\n","# 3Ô∏è‚É£ Load CLIP model for text embeddings\n","# -------------------------\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n","clip_model.eval()\n","print(f\"‚úÖ CLIP model loaded on {device}\")\n","\n","# -------------------------\n","# 4Ô∏è‚É£ Extract CLIP text embeddings\n","# -------------------------\n","def compute_clip_text_embeddings(texts, clip_model, batch_size=256, device='cuda'):\n","    \"\"\"Extract CLIP text embeddings\"\"\"\n","    all_embeds = []\n","\n","    for i in tqdm(range(0, len(texts), batch_size), desc=\"CLIP Text Embeddings\"):\n","        batch = texts[i:i+batch_size]\n","        batch_truncated = [str(t)[:300] for t in batch]\n","        text_tokens = clip.tokenize(batch_truncated, truncate=True).to(device)\n","\n","        with torch.no_grad():\n","            features = clip_model.encode_text(text_tokens)\n","            features = features / features.norm(dim=-1, keepdim=True)\n","\n","        all_embeds.append(features.cpu())\n","\n","    return torch.cat(all_embeds, dim=0)\n","\n","train_texts = data_final['catalog_content'].fillna(\"\").tolist()\n","\n","print(\"\\nüöÄ Extracting CLIP text embeddings...\")\n","clip_text_embeddings = compute_clip_text_embeddings(\n","    train_texts,\n","    clip_model,\n","    batch_size=256,\n","    device=device\n",")\n","print(f\"‚úÖ CLIP text embeddings: {clip_text_embeddings.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GjtRLkfxlgvr","executionInfo":{"status":"ok","timestamp":1760267226750,"user_tz":-330,"elapsed":77120,"user":{"displayName":"Nitish Rishi","userId":"10781579516426583515"}},"outputId":"c0df047b-ab37-4269-fdc0-dd83914aeaa7"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 338M/338M [00:02<00:00, 162MiB/s]\n"]},{"output_type":"stream","name":"stdout","text":["‚úÖ CLIP model loaded on cuda\n","\n","üöÄ Extracting CLIP text embeddings...\n"]},{"output_type":"stream","name":"stderr","text":["CLIP Text Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 293/293 [01:09<00:00,  4.21it/s]"]},{"output_type":"stream","name":"stdout","text":["‚úÖ CLIP text embeddings: torch.Size([75000, 512])\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["\n","# -------------------------\n","# 5Ô∏è‚É£ Compute Image-Text Alignment (THE SECRET WEAPON!)\n","# -------------------------\n","def compute_alignment_features(image_embeds, text_embeds):\n","    \"\"\"Image-text alignment catches listing quality issues\"\"\"\n","    min_len = min(image_embeds.shape[0], text_embeds.shape[0])\n","    image_embeds = image_embeds[:min_len]\n","    text_embeds = text_embeds[:min_len]\n","\n","    # Cosine similarity (already L2 normalized)\n","    similarity = (image_embeds * text_embeds).sum(dim=1, keepdim=True)\n","\n","    # Binary flags\n","    high_match = (similarity > 0.8).float()\n","    low_match = (similarity < 0.5).float()\n","\n","    return torch.cat([similarity, high_match, low_match], dim=1)\n","\n","print(\"\\nüîó Computing image-text alignment...\")\n","alignment_features = compute_alignment_features(img_tensor, clip_text_embeddings)\n","print(f\"‚úÖ Alignment features: {alignment_features.shape}\")\n","\n","# Statistics\n","print(f\"\\nüìä Alignment Statistics:\")\n","print(f\"   Mean similarity: {alignment_features[:, 0].mean():.3f}\")\n","print(f\"   High matches (>0.8): {alignment_features[:, 1].sum().item():.0f} ({alignment_features[:, 1].mean()*100:.1f}%)\")\n","print(f\"   Low matches (<0.5): {alignment_features[:, 2].sum().item():.0f} ({alignment_features[:, 2].mean()*100:.1f}%)\")\n","\n","# -------------------------\n","# 6Ô∏è‚É£ Extract structured features (last columns from MiniLM+structured)\n","# -------------------------\n","structured_cols = [\n","    'value', 'has_value', 'has_unit',\n","    'unit_final', 'unit_category',\n","    'qty_base', 'base_type',\n","    'word_count', 'char_count', 'avg_word_len',\n","    'bullet_count', 'num_digits',\n","    'is_organic', 'is_gluten_free', 'is_sugar_free',\n","    'is_vegan', 'is_new', 'has_pack_word', 'has_bundle'\n","]\n","num_structured = len(structured_cols)  # ~19 after encoding\n","\n","structured_features = train_text_struct[:, -num_structured:]\n","print(f\"\\nüì¶ Extracted structured features: {structured_features.shape}\")\n","\n","# -------------------------\n","# 7Ô∏è‚É£ Combine everything\n","# -------------------------\n","min_samples = min(\n","    img_tensor.shape[0],\n","    clip_text_embeddings.shape[0],\n","    alignment_features.shape[0],\n","    structured_features.shape[0]\n",")\n","\n","full_input = torch.cat([\n","    img_tensor[:min_samples],              # 512-dim\n","    clip_text_embeddings[:min_samples],    # 512-dim\n","    alignment_features[:min_samples],      # 3-dim\n","    structured_features[:min_samples]      # ~19-dim\n","], dim=1)\n","\n","sample_ids_tmp = sample_ids[:min_samples]\n","\n","\n","print(f\"\\n‚úÖ FINAL Combined input: {full_input.shape}\")\n","print(f\"   - CLIP Image: 512 dims\")\n","print(f\"   - CLIP Text: 512 dims\")\n","print(f\"   - Alignment: 3 dims\")\n","print(f\"   - Structured: {structured_features.shape[1]} dims\")\n","print(f\"   - TOTAL: {full_input.shape[1]} dims\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":471},"id":"B5yH_tM5l1-k","executionInfo":{"status":"error","timestamp":1760267320349,"user_tz":-330,"elapsed":400,"user":{"displayName":"Nitish Rishi","userId":"10781579516426583515"}},"outputId":"61e9f47b-f447-4b0a-f1bf-5e22effa5e76"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üîó Computing image-text alignment...\n","‚úÖ Alignment features: torch.Size([75000, 3])\n","\n","üìä Alignment Statistics:\n","   Mean similarity: 0.340\n","   High matches (>0.8): 0 (0.0%)\n","   Low matches (<0.5): 75000 (100.0%)\n","\n","üì¶ Extracted structured features: torch.Size([75000, 19])\n","\n","‚úÖ FINAL Combined input: torch.Size([75000, 1046])\n","   - CLIP Image: 512 dims\n","   - CLIP Text: 512 dims\n","   - Alignment: 3 dims\n","   - Structured: 19 dims\n","   - TOTAL: 1046 dims\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'list' object has no attribute 'shape'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-166091856.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   - Structured: {structured_features.shape[1]} dims\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   - TOTAL: {full_input.shape[1]} dims\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{sample_ids_tmp.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"]}]},{"cell_type":"code","source":["print(f\"{len(sample_ids_tmp)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jyjzQ8o6HMb0","executionInfo":{"status":"ok","timestamp":1760267390555,"user_tz":-330,"elapsed":12,"user":{"displayName":"Nitish Rishi","userId":"10781579516426583515"}},"outputId":"07ef383f-9746-472b-be61-917ac5c69d56"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["75000\n"]}]},{"cell_type":"code","source":["\n","test_input = torch.tensor(full_input.numpy(), dtype=torch.float)\n","# test_targets = torch.tensor(targets.numpy(), dtype=torch.float)\n","test_ids = torch.tensor(sample_ids_tmp)\n","\n","\n","print(f\"\\n‚úÖ Train: {test_input.shape}\")\n","\n","# -------------------------\n","# 9Ô∏è‚É£ Save\n","# -------------------------\n","save_dir = os.path.join(base_dir, \"combined_CLIP_final\")\n","os.makedirs(save_dir, exist_ok=True)\n","save_path = os.path.join(save_dir, \"clip_test_with_alignment.pt\")\n","\n","torch.save({\n","    \"test_input\": test_input,\n","    \"test_ids\": test_ids,\n","    # \"test_targets\": test_targets\n","}, save_path)\n","\n","print(f\"\\n‚úÖ Saved to: {save_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KPTkr-P3l9-s","executionInfo":{"status":"ok","timestamp":1760267431773,"user_tz":-330,"elapsed":1670,"user":{"displayName":"Nitish Rishi","userId":"10781579516426583515"}},"outputId":"48f44261-4f90-4ae6-9ba2-f43b41ea8ee4"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","‚úÖ Train: torch.Size([75000, 1046])\n","\n","‚úÖ Saved to: /content/drive/MyDrive/amazon_ml_challenge/combined_CLIP_final/clip_test_with_alignment.pt\n"]}]},{"cell_type":"markdown","source":["## Test set eval and submission file making"],"metadata":{"id":"YRrLbhr7pUKK"}},{"cell_type":"code","source":["# =========================================================================\n","# Test Set Evaluation with Ensemble Models\n","# =========================================================================\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","import pandas as pd\n","from torch.utils.data import DataLoader, TensorDataset\n","from tqdm import tqdm\n","import os\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# =========================================================================\n","# Model Definition (Same as training)\n","# =========================================================================\n","class RegressionMLP(nn.Module):\n","    def __init__(self, input_dim):\n","        super().__init__()\n","        self.model = nn.Sequential(\n","            nn.Linear(input_dim, 1024),\n","            nn.ReLU(),\n","            nn.BatchNorm1d(1024),\n","            nn.Dropout(0.3),\n","\n","            nn.Linear(1024, 512),\n","            nn.ReLU(),\n","            nn.BatchNorm1d(512),\n","            nn.Dropout(0.3),\n","\n","            nn.Linear(512, 256),\n","            nn.ReLU(),\n","            nn.BatchNorm1d(256),\n","            nn.Dropout(0.2),\n","\n","            nn.Linear(256, 1)\n","        )\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","# =========================================================================\n","# Load Ensemble Models\n","# =========================================================================\n","print(\"\\n\" + \"=\"*70)\n","print(\"üìÇ Loading Ensemble Models\")\n","print(\"=\"*70)\n","\n","save_dir = '/content/drive/MyDrive/amazon_ml_challenge/ensemble_CLIP_models'\n","metadata_path = os.path.join(save_dir, 'ensemble_metadata.pt')\n","\n","# Load metadata\n","metadata = torch.load(metadata_path, weights_only=False)\n","input_dim = metadata['input_dim']\n","print(f\"Input dimension: {input_dim}\")\n","print(f\"Training MAE: {metadata['mae']:.4f}\")\n","print(f\"Training RMSE: {metadata['rmse']:.4f}\")\n","\n","# Load all 10 models\n","models = []\n","for i in range(10):\n","    model_path = os.path.join(save_dir, f'clip_ensemble_model_{i}.pt')\n","    model = RegressionMLP(input_dim).to(device)\n","    model.load_state_dict(torch.load(model_path, map_location=device, weights_only=False))\n","    model.eval()\n","    models.append(model)\n","    print(f\"‚úÖ Loaded model {i+1}/10\")\n","\n","print(f\"\\n‚úÖ All models loaded successfully!\")\n","\n","# =========================================================================\n","# Load Test Data\n","# =========================================================================\n","print(\"\\n\" + \"=\"*70)\n","print(\"üìä Loading Test Data\")\n","print(\"=\"*70)\n","\n","# Load your CLIP-processed test data\n","test_data_path = '/content/drive/MyDrive/amazon_ml_challenge/combined_CLIP_final/clip_test_with_alignment.pt'\n","test_data = torch.load(test_data_path)\n","\n","test_input = test_data['test_input'].to(device)\n","test_ids = test_data['test_ids']  # Assuming you saved IDs\n","\n","print(f\"Test data shape: {test_input.shape}\")\n","print(f\"Number of test samples: {len(test_ids)}\")\n","\n","# =========================================================================\n","# Ensemble Prediction\n","# =========================================================================\n","print(\"\\n\" + \"=\"*70)\n","print(\"üîÆ Making Ensemble Predictions\")\n","print(\"=\"*70)\n","\n","# Batch prediction for efficiency\n","batch_size = 512\n","test_loader = DataLoader(\n","    TensorDataset(test_input),\n","    batch_size=batch_size,\n","    shuffle=False\n",")\n","\n","all_predictions = []\n","\n","# Get predictions from each model\n","for model_idx, model in enumerate(models):\n","    print(f\"Predicting with model {model_idx+1}/10...\")\n","    model_preds = []\n","\n","    with torch.no_grad():\n","        for (batch_x,) in tqdm(test_loader, desc=f\"Model {model_idx+1}\"):\n","            batch_x = batch_x.to(device)\n","            pred = model(batch_x)\n","            model_preds.append(pred.cpu())\n","\n","    model_preds = torch.cat(model_preds, dim=0)\n","    all_predictions.append(model_preds)\n","\n","# Average predictions across all models\n","print(\"\\nüìä Averaging predictions from all models...\")\n","ensemble_predictions = torch.stack(all_predictions).mean(dim=0).squeeze()\n","\n","# Clamp predictions in log-space (same as validation)\n","max_price = 4000\n","max_log_value = np.log1p(max_price)\n","ensemble_predictions_clipped = torch.clamp(ensemble_predictions, min=0, max=max_log_value)\n","\n","# Convert from log space to original scale\n","final_predictions = np.expm1(ensemble_predictions_clipped.numpy())\n","\n","print(f\"\\n‚úÖ Predictions complete!\")\n","print(f\"Prediction range: [{final_predictions.min():.2f}, {final_predictions.max():.2f}]\")\n","print(f\"Prediction mean: {final_predictions.mean():.2f}\")\n","print(f\"Prediction median: {np.median(final_predictions):.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"okg82RIUmzlD","executionInfo":{"status":"ok","timestamp":1760267568839,"user_tz":-330,"elapsed":11217,"user":{"displayName":"Nitish Rishi","userId":"10781579516426583515"}},"outputId":"03b26de0-845c-4c93-a6f1-044296c30519"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","üìÇ Loading Ensemble Models\n","======================================================================\n","Input dimension: 1046\n","Training MAE: 12.1486\n","Training RMSE: 34.1616\n","‚úÖ Loaded model 1/10\n","‚úÖ Loaded model 2/10\n","‚úÖ Loaded model 3/10\n","‚úÖ Loaded model 4/10\n","‚úÖ Loaded model 5/10\n","‚úÖ Loaded model 6/10\n","‚úÖ Loaded model 7/10\n","‚úÖ Loaded model 8/10\n","‚úÖ Loaded model 9/10\n","‚úÖ Loaded model 10/10\n","\n","‚úÖ All models loaded successfully!\n","\n","======================================================================\n","üìä Loading Test Data\n","======================================================================\n","Test data shape: torch.Size([75000, 1046])\n","Number of test samples: 75000\n","\n","======================================================================\n","üîÆ Making Ensemble Predictions\n","======================================================================\n","Predicting with model 1/10...\n"]},{"output_type":"stream","name":"stderr","text":["Model 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147/147 [00:00<00:00, 242.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Predicting with model 2/10...\n"]},{"output_type":"stream","name":"stderr","text":["Model 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147/147 [00:00<00:00, 227.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Predicting with model 3/10...\n"]},{"output_type":"stream","name":"stderr","text":["Model 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147/147 [00:00<00:00, 335.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Predicting with model 4/10...\n"]},{"output_type":"stream","name":"stderr","text":["Model 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147/147 [00:00<00:00, 347.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Predicting with model 5/10...\n"]},{"output_type":"stream","name":"stderr","text":["Model 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147/147 [00:00<00:00, 339.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Predicting with model 6/10...\n"]},{"output_type":"stream","name":"stderr","text":["Model 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147/147 [00:00<00:00, 350.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Predicting with model 7/10...\n"]},{"output_type":"stream","name":"stderr","text":["Model 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147/147 [00:00<00:00, 338.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Predicting with model 8/10...\n"]},{"output_type":"stream","name":"stderr","text":["Model 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147/147 [00:00<00:00, 226.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Predicting with model 9/10...\n"]},{"output_type":"stream","name":"stderr","text":["Model 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147/147 [00:00<00:00, 343.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Predicting with model 10/10...\n"]},{"output_type":"stream","name":"stderr","text":["Model 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147/147 [00:00<00:00, 279.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Averaging predictions from all models...\n","\n","‚úÖ Predictions complete!\n","Prediction range: [1.07, 4000.00]\n","Prediction mean: 19.99\n","Prediction median: 15.74\n"]}]},{"cell_type":"code","source":["\n","# =========================================================================\n","# Create Submission File\n","# =========================================================================\n","print(\"\\n\" + \"=\"*70)\n","print(\"üíæ Creating Submission File\")\n","print(\"=\"*70)\n","\n","submission_df = pd.DataFrame({\n","    'id': test_ids,\n","    'entity_value': final_predictions\n","})\n","\n","# Save submission\n","submission_path = '/content/drive/MyDrive/amazon_ml_challenge/test_predictions_ensemble.csv'\n","submission_df.to_csv(submission_path, index=False)\n","\n","print(f\"‚úÖ Submission saved to: {submission_path}\")\n","print(f\"\\nFirst 10 predictions:\")\n","print(submission_df.head(10))\n","\n","# =========================================================================\n","# Additional Analysis\n","# =========================================================================\n","print(\"\\n\" + \"=\"*70)\n","print(\"üìà Prediction Statistics\")\n","print(\"=\"*70)\n","\n","print(f\"\\nDescriptive Statistics:\")\n","print(f\"  Count: {len(final_predictions)}\")\n","print(f\"  Mean: {final_predictions.mean():.4f}\")\n","print(f\"  Std: {final_predictions.std():.4f}\")\n","print(f\"  Min: {final_predictions.min():.4f}\")\n","print(f\"  25%: {np.percentile(final_predictions, 25):.4f}\")\n","print(f\"  50%: {np.median(final_predictions):.4f}\")\n","print(f\"  75%: {np.percentile(final_predictions, 75):.4f}\")\n","print(f\"  Max: {final_predictions.max():.4f}\")\n","\n","# Check prediction variance across models\n","print(f\"\\nüîç Ensemble Variance Analysis:\")\n","pred_std = torch.stack(all_predictions).std(dim=0).squeeze().numpy()\n","print(f\"  Mean std across models: {pred_std.mean():.4f}\")\n","print(f\"  Max std across models: {pred_std.max():.4f}\")\n","print(f\"  Min std across models: {pred_std.min():.4f}\")\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"‚úÖ EVALUATION COMPLETE!\")\n","print(\"=\"*70)\n","\n","# =========================================================================\n","# Optional: Save individual model predictions for analysis\n","# =========================================================================\n","save_individual = False  # Set to True if you want to save individual predictions\n","\n","if save_individual:\n","    print(\"\\nüíæ Saving individual model predictions...\")\n","    individual_preds = {}\n","    for i, preds in enumerate(all_predictions):\n","        individual_preds[f'model_{i}'] = np.expm1(preds.numpy())\n","\n","    individual_df = pd.DataFrame(individual_preds)\n","    individual_df['id'] = test_ids\n","    individual_df['ensemble_mean'] = final_predictions\n","\n","    individual_path = '/content/drive/MyDrive/amazon_ml_challenge/individual_predictions.csv'\n","    individual_df.to_csv(individual_path, index=False)\n","    print(f\"‚úÖ Individual predictions saved to: {individual_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2APFeQemnWxS","executionInfo":{"status":"ok","timestamp":1760267575044,"user_tz":-330,"elapsed":144,"user":{"displayName":"Nitish Rishi","userId":"10781579516426583515"}},"outputId":"6b5e91dd-c9ec-4f59-f693-d51e350a4903"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","üíæ Creating Submission File\n","======================================================================\n","‚úÖ Submission saved to: /content/drive/MyDrive/amazon_ml_challenge/test_predictions_ensemble.csv\n","\n","First 10 predictions:\n","       id  entity_value\n","0  100179     15.691438\n","1  245611     15.215573\n","2  146263     23.166376\n","3   95658     21.184490\n","4   36806     20.689602\n","5  148239      7.142827\n","6   92659      5.977146\n","7    3780     17.961704\n","8  196940     15.539577\n","9   20472      8.523639\n","\n","======================================================================\n","üìà Prediction Statistics\n","======================================================================\n","\n","Descriptive Statistics:\n","  Count: 75000\n","  Mean: 19.9899\n","  Std: 22.2912\n","  Min: 1.0699\n","  25%: 10.0801\n","  50%: 15.7399\n","  75%: 23.6990\n","  Max: 4000.0020\n","\n","üîç Ensemble Variance Analysis:\n","  Mean std across models: 0.2175\n","  Max std across models: 114.8519\n","  Min std across models: 0.0220\n","\n","======================================================================\n","‚úÖ EVALUATION COMPLETE!\n","======================================================================\n"]}]},{"cell_type":"code","source":["submission_df = pd.DataFrame({\n","    'sample_id': test_ids,\n","    'price': final_predictions\n","})"],"metadata":{"id":"uVixn0mBH50Q","executionInfo":{"status":"ok","timestamp":1760267727335,"user_tz":-330,"elapsed":3,"user":{"displayName":"Nitish Rishi","userId":"10781579516426583515"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["submission_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"pS1ciLAhIKi3","executionInfo":{"status":"ok","timestamp":1760267734238,"user_tz":-330,"elapsed":134,"user":{"displayName":"Nitish Rishi","userId":"10781579516426583515"}},"outputId":"5588595b-f94b-403b-bf16-c956581a6aa0"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       sample_id      price\n","0         100179  15.691438\n","1         245611  15.215573\n","2         146263  23.166376\n","3          95658  21.184490\n","4          36806  20.689602\n","...          ...        ...\n","74995      93616  21.545609\n","74996     249434  12.976159\n","74997     162217   4.529245\n","74998     230487  17.538809\n","74999     279477  10.395247\n","\n","[75000 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-dd3a9809-8da8-4012-80b3-a76b6c53b220\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sample_id</th>\n","      <th>price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>100179</td>\n","      <td>15.691438</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>245611</td>\n","      <td>15.215573</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>146263</td>\n","      <td>23.166376</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>95658</td>\n","      <td>21.184490</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>36806</td>\n","      <td>20.689602</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>74995</th>\n","      <td>93616</td>\n","      <td>21.545609</td>\n","    </tr>\n","    <tr>\n","      <th>74996</th>\n","      <td>249434</td>\n","      <td>12.976159</td>\n","    </tr>\n","    <tr>\n","      <th>74997</th>\n","      <td>162217</td>\n","      <td>4.529245</td>\n","    </tr>\n","    <tr>\n","      <th>74998</th>\n","      <td>230487</td>\n","      <td>17.538809</td>\n","    </tr>\n","    <tr>\n","      <th>74999</th>\n","      <td>279477</td>\n","      <td>10.395247</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>75000 rows √ó 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd3a9809-8da8-4012-80b3-a76b6c53b220')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-dd3a9809-8da8-4012-80b3-a76b6c53b220 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-dd3a9809-8da8-4012-80b3-a76b6c53b220');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-c621fbe8-df4d-42d9-8ac0-65beb06c4e84\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c621fbe8-df4d-42d9-8ac0-65beb06c4e84')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-c621fbe8-df4d-42d9-8ac0-65beb06c4e84 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_189002ea-ea79-4c78-864b-442137eed2a4\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('submission_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_189002ea-ea79-4c78-864b-442137eed2a4 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('submission_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"submission_df","summary":"{\n  \"name\": \"submission_df\",\n  \"rows\": 75000,\n  \"fields\": [\n    {\n      \"column\": \"sample_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 86763,\n        \"min\": 1,\n        \"max\": 299439,\n        \"num_unique_values\": 75000,\n        \"samples\": [\n          217392,\n          209156,\n          262333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 74629,\n        \"samples\": [\n          21.413864135742188,\n          20.846637725830078,\n          16.104520797729492\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":[],"metadata":{"id":"Orv1FV0HIgpC"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Orv1FV0HIgcC","executionInfo":{"status":"ok","timestamp":1760267795734,"user_tz":-330,"elapsed":96,"user":{"displayName":"Nitish Rishi","userId":"10781579516426583515"}},"outputId":"d30f4b57-680f-4256-b33a-48ad5236aef9"},"source":["# Save the DataFrame as a CSV file to the local Colab environment\n","submission_csv_path = \"/content/submission_predictions.csv\"\n","submission_df.to_csv(submission_csv_path, index=False)\n","\n","print(f\"‚úÖ DataFrame saved as CSV to: {submission_csv_path}\")"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ DataFrame saved as CSV to: /content/submission_predictions.csv\n"]}]}]}